---
title: "Basic analyses and heatmaps with dlptools"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Basic analyses and heatmaps with dlptools}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# dlptools

dlptools will help with basic file manipulation of DLP pipeline out and adding of genomic features to read bins for filtering and classification of changes. Also included are a few standard plots that are commonly made.

## Installation

You can install the development version of dlptools from [GitHub](https://github.com/) with:

``` r
# install.packages("devtools")
devtools::install_github("molonc/dlptools")
```

## Common Analysis Tasks

These are a few steps that are often taken to start a DLP analysis.

```{r example, message=FALSE, warning=FALSE}
library(fs)
library(dplyr)
library(dlptools)

# a file path to where some directories with DLP data lives. Expected structure
# discussed in README.md
dlp_dir <- "/projects/molonc/scratch/bfurman/dlp_testdata/"

# looks something like this
fs::dir_tree(dlp_dir, recurse = 1)
```


First step is usually to import the cell specific metrics and mark which cells are good ones to use for downstream analyses.

This example uses some typical thresholds, but you should think about these in relation to your project and sequence data at hand.

```{r}
metrics <- dlptools::import_dlp_files(dlp_dir, "metrics")

# This example is of some commonly used thresholds and things
metrics <- metrics |>
  dplyr::mutate(
    good_cell = dplyr::if_else(
      quality >= 0.75 & # cells of high RF quality
        !is_control & # non-control cells
        cell_call == "C1" & # live cells
        !is_s_phase & # that are not estimated to be in S-phase
        total_mapped_reads >= 250000, # and have a reasonable amount of reads
      TRUE,
      FALSE
    )
  )
```

Loading the reads data would be the next step. These are 500 Kb bins where copy number estimates are converted into integer state calls by HMMCopy.

Similar to the metrics, we want to mark which bins are good to use for analyses with a few thresholds:

```{r}
reads <- dlptools::import_dlp_files(dlp_dir, "reads")


# first, let's mark the ones that fall into regions we want to mask
# see README.md for accessing this file.
reads <- dlptools::mark_mask_regions(
  reads,
  mask_f = "../meta_data/blacklist_2023.07.17.txt"
)

# then, we can add a column for which count as "good" bins
reads <- reads |>
  dplyr::mutate(
    good_bin = dplyr::if_else(
      !mask & # does not fall into mask region
        gc > -1 & # bin went through GC correciton
        map > 0.99, # read bin is in a high mappability region
      TRUE,
      FALSE
    )
  )
```

Now we can combine the reads state calls with the metrics, i.e., contextualizing the state calls with the cell level metrics:

```{r}
reads <- dplyr::left_join(
  reads, metrics,
  by = "cell_id",
)

# and then create a filtered set of reads for analysis
reads_filt <- dplyr::filter(reads, good_cell & good_bin)


# many columns of data available. Here is a subset
reads_filt[1:4, 2:10]
```


You might also want reads summarized into segments, which are collapsed blocks of read bins that have been assigned the same state. 

The DLP pipeline does produce a segments file, which you can import with:

 `dlptools::import_dlp_files(dlp_dir, "segs")`

but that file was made with internal filters and settings that you probably don't know or want.

So we can create one from our filtered reads:

```{r}
#  This can take a bit to run if you have a lot of runs combined.
segs_filt <- dlptools::reads_to_segs_with_filters(reads_filt)

# this is now runs of adjacent read bins with identical states collapesed
# into a single bin. Of course, bins are no longer of equal size.
segs_filt[1:4, ]
```



## Plotting Trees and Heatmaps

A common plot from a DLP analysis is to build a tree with some method ([sitka](https://github.com/molonc/sitka_wrapper/tree/main), or hdbscan) and then plot it next to a heatmap of read state calls. The function `dlptools::create_tree_copynumber_heatmap()` is designed to do just that. It is a wrapper around several independent steps and the full code with individual functions is available in the repo at `R/plot_tree_heatmap.R`.

The point of the plot is to bring together a tree, with clone labels, and state calls. If you have other annotations, those can be added too.

Here we'll walk through plot creation with HDBScan. This requires installing [signals](https://github.com/shahcompbio/signals) in addition to this package.


This example is assuming you followed the steps above to create a set of filtered reads.

```{r}
library(signals)


clusters <- signals::umap_clustering(
  reads_filt,
  minPts = 50, field = "state"
)

# if you see an error like:
#     An error occurred in umap calculation: function 'as_cholmod_sparse' not
#     provided by package 'Matrix'
# you might need to install some older package versions
# remotes::install_version("Matrix", version = "1.6-1")
# install.packages("irlba", type = "source")
# https://github.com/bwlewis/irlba/issues/70


# need to prep the reads data
reads_f_wide <- dlptools::convert_long_reads_to_wide(reads_filt)

# now we can make the plot
dlptools::create_tree_copynumber_heatmap(
  phylo_tree = clusters$tree,
  states_df = reads_f_wide,
  clones_df = clusters$clustering,
  # can save direct to file by adding:
  # remove to print to screen (but plots are typically large)
  file_name = "../example_heatmaps/example_hdbscan.png"
)

# lets say we had some annotation we wanted to add too, these are done by
# matching sample IDs in cell_id names.
# this could be read froma file with dlptools::import_annotations_df()
# but will just prep this example by hand
anno_df <- tibble(
  # bit of a boring example, because we only have one sample and one library
  sample_id = c("AT21614"),
  passage = c("p10"),
  somthing_else = c("featureA")
)

dlptools::create_tree_copynumber_heatmap(
  phylo_tree = clusters$tree,
  states_df = reads_f_wide,
  clones_df = clusters$clustering,
  annos_df = anno_df
)

# this plot will look bad in the vignette, see the example ouputs in the
# example_heatmaps/ folder.
```


If you've run sitka (perhaps using the [sitka_wrapper](https://github.com/molonc/sitka_wrapper)), you can read in the newick tree file created and do much the same plot. Presumably you would have also used the leiden_cut method for clone labelling, and will need that file too. 

```{r}
# here, pulled from the example files in the tree_cutting/ section of the
# sitka_wrapper repo linked above
sitka_files <- "/projects/molonc/aparicio_lab/bfurman/code/sitka_wrapper/tree_cutting/example_inputs/"
clones_f <- fs::path_join(c(sitka_files, "leiden_clones_reso010_nb10.csv"))
sitka_reads_f <- fs::path_join(c(sitka_files, "filtered_cell_state_calls.csv.gz"))
sitka_tree_f <- fs::path_join(c(sitka_files, "tree.newick"))

# sitka trees need a little cleaning, so run through the tree formatting
# function to drop 'locus_' values at tips, and clean off 'cell_' names from
# tree leafs
sitka_tree <- dlptools::import_tree(sitka_tree_f) |>
  dlptools::format_sitka_tree()

# expects a file with columns of: cell_id, clone_id
clones <- dlptools::import_clones(clones_f)

# standard sitka input format
sitka_reads <- dlptools::import_wideformat_states_file(sitka_reads_f)

# set up or read external annotations file with:
# dlptools::import_annotations_df(anno_file)
anno_df <- tibble(
  # bit of a boring example, because we only have one sample and one library
  sample_id = c("AT21552", "AT21350"),
  passage = c("p3", "p23"),
  somthing_else = c("featureA", "featureB")
)

dlptools::create_tree_copynumber_heatmap(
  phylo_tree = sitka_tree,
  states_df = sitka_reads,
  clones_df = clones,
  annos_df = anno_df,
  file_name = "../example_heatmaps/example_sitka.png"
)
```
