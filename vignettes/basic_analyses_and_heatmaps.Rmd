---
title: "Basic analyses and heatmaps with dlptools"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Basic analyses and heatmaps with dlptools}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  message = FALSE,
  warning = FALSE
)
```

# dlptools

dlptools will help with basic file manipulation of DLP pipeline out and adding of genomic features to read bins for filtering and classification of changes. Also included are a few standard plots that are commonly made.

## Installation

You can install the development version of dlptools from [GitHub](https://github.com/) with:

``` r
# install.packages("devtools")
devtools::install_github("molonc/dlptools")
```

## Common Analysis Tasks

These are a few steps that are often taken to start a DLP analysis.

```{r example, message=FALSE, warning=FALSE}
library(fs)
library(dplyr)
library(dlptools)

# a file path to where some directories with DLP data lives. Expected structure
# discussed in README.md
dlp_dir <- "/projects/molonc/scratch/bfurman/dlp_testdata/"

# looks something like this
fs::dir_tree(dlp_dir, recurse = 1)
```


First step is usually to import the cell specific metrics and mark which cells are good ones to use for downstream analyses.

This example uses some typical thresholds, but you should think about these in relation to your project and sequence data at hand.


Importing data:

```{r}
metrics <- dlptools::import_dlp_files(dlp_dir, "metrics")
```

or really, however you like to load a directory of tsvs, this is just a convenience function as DLP output tends not to change run to run.


Here we can set some thresholds to define "good cells". These here are just a suggestion with some commonly used thresholds. These could be project specific.

```{r}
metrics <- metrics |>
  dplyr::mutate(
    good_cell = dplyr::if_else(
      quality >= 0.75 & # cells of high RF quality
        !is_control & # non-control cells
        cell_call == "C1" & # live cells
        !is_s_phase & # that are not estimated to be in S-phase
        total_mapped_reads >= 250000, # and have a reasonable amount of reads
      TRUE,
      FALSE
    )
  )
```


Loading the reads data would be the next step. These are 500 Kb bins where copy number estimates are converted into integer state calls by HMMCopy.

Similar to the metrics, we want to mark which bins are good to use for analyses with a few thresholds:

```{r}
reads <- dlptools::import_dlp_files(dlp_dir, "reads")
```


first, let's mark the ones that fall into regions we want to mask (see README.md for accessing this file).

```{r}
reads <- dlptools::mark_mask_regions(
  reads,
  mask_f = "../meta_data/blacklist_2023.07.17.txt"
)
```


then, we can add a column for which count as "good" bins. Again, just sugestions with commonly used thresholds:

```{r}
reads <- reads |>
  dplyr::mutate(
    good_bin = dplyr::if_else(
      !mask & # does not fall into mask region
        gc > -1 & # bin went through GC correciton
        map > 0.99, # read bin is in a high mappability region
      TRUE,
      FALSE
    )
  )
```

Now we can combine the reads state calls with the metrics, i.e., contextualizing the state calls with the cell level metrics:

```{r}
reads <- dplyr::left_join(
  reads, metrics,
  by = "cell_id",
)
```

and then create a filtered set of reads for analysis
```{r}
reads_filt <- dplyr::filter(reads, good_cell & good_bin)


# many columns of data available. Here is a subset
reads_filt[1:4, 2:10]
```


A common need is to have reads summarized into segments, which are collapsed blocks of read bins that have been assigned the same state. 

The DLP pipeline does produce a segments file, which you can import with:

 `dlptools::import_dlp_files(dlp_dir, "segs")`

but that file was made with internal filters and settings that you probably don't know or want.

So we can create one from our filtered reads:

```{r}
#  This can take a bit to run if you have a lot of runs combined.
segs_filt <- dlptools::reads_to_segs_with_filters(reads_filt)

# this is now runs of adjacent read bins with identical states collapesed
# into a single bin. Of course, bins are no longer of equal size.
segs_filt[1:4, ]
```



## Plotting Trees and Heatmaps

A common plot from a DLP analysis is to build a tree with some method ([sitka](https://github.com/molonc/sitka_wrapper/tree/main), or hdbscan) and then plot it next to a heatmap of read state calls. The function `dlptools::create_tree_copynumber_heatmap()` is designed to do just that. It is a wrapper around several independent steps and the full code with individual functions is available in the repo at `R/plot_tree_heatmap.R`.

The point of the plot is to bring together a tree, with clone labels, and state calls. If you have other annotations, those can be added too.

Here we'll walk through plot creation with HDBScan. This requires installing [signals](https://github.com/shahcompbio/signals) in addition to this package.


This example is assuming you followed the steps above to create a set of filtered reads.


First, need to run umap clustering and in the process create a tree with hdbscan:

```{r}
library(signals)

clusters <- signals::umap_clustering(
  reads_filt,
  minPts = 50, field = "state"
)

# if you see an error like:
#     An error occurred in umap calculation: function 'as_cholmod_sparse' not
#     provided by package 'Matrix'
# you might need to install some older package versions
# remotes::install_version("Matrix", version = "1.6-1")
# install.packages("irlba", type = "source")
# https://github.com/bwlewis/irlba/issues/70
```


Then prep the reads data (continuing with the data from example above) for plotting:

```{r}
reads_f_wide <- dlptools::convert_long_reads_to_wide(reads_filt)
```


Now we can make the plot:

```{r}
dlptools::create_tree_copynumber_heatmap(
  phylo_tree = clusters$tree,
  states_df = reads_f_wide,
  clones_df = clusters$clustering,
  # can save direct to file by adding:
  # remove to print to screen (but plots are typically large)
  file_name = "../example_heatmaps/example_hdbscan.png"
)
```

here we write directly to a file. You can print to screen by not including a `file_name` argument, but these plots are big and are often best just dumped to a file to look at.

<br>
<br>
<br>

Lets say we had some annotation we wanted to add too (as left side columns on the heatmap). This is done by matching sample IDs in cell_id names, and could be read from a t(c)sv file with `dlptools::import_annotations_df()`. 

But for this example will just prep by hand:

```{r}
anno_df <- tibble(
  # bit of a boring example, because we only have one sample and one library
  sample_id = c("AT21614"),
  passage = c("p10"),
  somthing_else = c("featureA")
)
```


And then we can pass this tibble to the plotting code to be added.
```{r}
dlptools::create_tree_copynumber_heatmap(
  phylo_tree = clusters$tree,
  states_df = reads_f_wide,
  clones_df = clusters$clustering,
  annos_df = anno_df
)
```


**This plot will look bad in the vignette, see the example ouputs in the example_heatmaps/ folder.**

<br>
<br>
<br>

If you've run sitka (perhaps using the [sitka_wrapper](https://github.com/molonc/sitka_wrapper)), you can read in the newick tree file created and do much the same plot. Presumably you would have also used the leiden_cut method for clone labelling, and will need that file too. 

```{r}
# here, pulled from the example files in the tree_cutting/ section of the
# sitka_wrapper repo linked above
sitka_files <- "/projects/molonc/aparicio_lab/bfurman/code/sitka_wrapper/tree_cutting/example_inputs/"
clones_f <- fs::path_join(c(sitka_files, "leiden_clones_reso010_nb10.csv"))
sitka_reads_f <- fs::path_join(c(sitka_files, "filtered_cell_state_calls.csv.gz"))
sitka_tree_f <- fs::path_join(c(sitka_files, "tree.newick"))
```


Sitka trees need a little cleaning, so run through the tree formatting function to drop 'locus_' values at tips, and clean off 'cell_' names from tree leafs.

There are also other importing functions that will help set the data up correctly:

```{r}
# import and format the tree file
sitka_tree <- dlptools::import_tree(sitka_tree_f) |>
  dlptools::format_sitka_tree()

# expects a file with columns of: cell_id, clone_id
clones <- dlptools::import_clones(clones_f)

# standard sitka input format
sitka_reads <- dlptools::import_wideformat_states_file(sitka_reads_f)

# set up or read external annotations file with:
# dlptools::import_annotations_df(anno_file)
anno_df <- tibble(
  # bit of a boring example, because we only have one sample and one library
  sample_id = c("AT21552", "AT21350"),
  passage = c("p3", "p23"),
  somthing_else = c("featureA", "featureB")
)
```



and now we can create the plot:

```{r}
dlptools::create_tree_copynumber_heatmap(
  phylo_tree = sitka_tree,
  states_df = sitka_reads,
  clones_df = clones,
  annos_df = anno_df,
  file_name = "../example_heatmaps/example_sitka.png"
)
```
